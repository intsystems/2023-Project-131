\documentclass{beamer}
\beamertemplatenavigationsymbolsempty
\usecolortheme{beaver}
\setbeamertemplate{blocks}[rounded=true, shadow=true]
\setbeamertemplate{footline}[page number]
%
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amssymb,amsfonts,amsmath,mathtext}
\usepackage{subfig}
\usepackage[all]{xy} % xy package for diagrams
\usepackage{array}
\usepackage{multicol}% many columns in slide
\usepackage{hyperref}% urls
\usepackage{hhline}%tables
% Your figures are here:
\graphicspath{ {../figures/} }

\DeclareMathOperator*{\norm}{\text{norm}}

%----------------------------------------------------------------------------------------------------------
\title[\hbox to 56mm{Итеративное улучшение}]{Итеративное улучшение тематической \\ модели с обратной связью от пользователя}
\author[А.\,И. Горбулев]{Алексей Ильич Горбулев}
\institute{Московский физико-технический институт}
\date{\footnotesize
\par\smallskip\emph{Курс:} Моя первая научная статья/Группа Б05-021а
% Консультировался с В. А. Алексеевым по следующему поводу, так как схема такова: студент с Алексеевым, Алексеев с Воронцовым
\par\smallskip\emph{Эксперт:} д. ф.-м. н. К.\,В.~Воронцов
\par\smallskip\emph{Консультант:} В.\,А.~Алексеев
\par\bigskip\small 2023}
%----------------------------------------------------------------------------------------------------------
\begin{document}
%----------------------------------------------------------------------------------------------------------
\begin{frame}
\thispagestyle{empty}
\maketitle
\end{frame}
%-----------------------------------------------------------------------------------------------------

\begin{frame}{Цель исследования}
    \textbf{Мотивация:} тематические модели неустойчивы, неполны

    \textbf{Цель исследования:} получить \textit{интерпретируемую} тематическую модель за некоторое число итераций

    \textbf{Метод:} итеративное улучшение тематической модели c использованием регуляризаторов пользовательской разметки тем на релевантные, нерелевантные и <<мусорные>>
\end{frame}

\begin{frame}{Литература}
\begin{itemize}
    \item Alekseev V. et al. "TopicBank: Collection of coherent topics using multiple model training with their further use for topic model validation"
    \item Victor Bulatov, Evgeny Egorov, Eugenia Veselova, Darya Polyudova, Vasiliy Alekseev, Alexey Goncharov, Konstantin Vorontsov. “TopicNet: Making Additive Regularisation for Topic Modelling Accessible”
    \item Воронцов К.В. "Вероятностное тематическое моделирование: теория, модели, алгоритмы и проект BigARTM"
\end{itemize}
\end{frame}

\begin{frame}{О тематическом моделировании и ARTM}
    \begin{itemize}
        \item $D$ — множество (коллекция) документов
        \item $W$ — множество термов \\ {\footnotesize Термами могут быть слова в нормальной форме, словосочетания. Каждый документ $d \in D$ представляет собой последовательность термов.}
        \item $T$ — множество тем \\ {\footnotesize Как правило, количество тем $|T|$ заранее задано.}
    \end{itemize}

    При построении вероятностной тематической модели
    $$p (w \mid d) = \sum \limits_{t \in T} p (w \mid t) p (t \mid d) - \sum \limits_{t \in T} \varphi_{wt} \theta_{td}$$
    в подходе ARTM происходит максимизация $\log$ правдоподобия с $k$ регуляризаторами $R_i$:
    $$\sum \limits_{d, w} n_{dw} \ln \sum \limits_{t} \varphi_{wt} \theta_{td} + \sum \limits_{i = 1}^k \tau_i R_i (\Phi, \Theta) \to \max \limits_{\Phi, \Theta}$$
\end{frame}
%-----------------------------------------------------------------------------------------------------

\begin{frame}{О тематическом моделировании и ARTM}

Далее применяется EM-алгоритм.

\begin{itemize}
    \item E-шаг:
    $$p_{tdw} = \norm \limits_{t \in T} (\varphi_{wt} \theta_{td})$$
    \item M-шаг: 
    $$
    \varphi_{wt} = \norm \limits_{w \in W} (n_{wt} + \varphi_{wt} \frac{\partial R}{\partial \varphi_{wt}})
    $$
    $$
    \theta_{td} = \norm \limits_{t \in T} (n_{td} + \theta_{td} \frac{\partial R}{\partial \theta_{td}})
    $$
\end{itemize}

\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Постановка задачи}

Пусть $D$ — коллекция документов, количество тем $|T|$ задано заранее. \\
После обучения базовой тематической модели $M_0$ каждая из тем $t \in T$ отнесена пользователем в одну из трёх категорий:
\begin{itemize}
    \item $T_+$ (релевантные, \textit{имеющие отношение к исследовани.})
    \item $T_0$ (нерелевантные, \textit{дублирующие релевантные})
    \item $T_-$ («мусорные», \textit{не имеющие отношение к исследованию})
\end{itemize}
После обучения новой тематической модели $M_1$ $|T_+|$ должно увеличиться, и должно быть сохранено как можно больше тем из $T_+$, а $|T_-|$ должно уменьшиться. Процесс продолжается итеративно.

\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Решение}
На каждой итерации:
\begin{itemize}
    \item С помощью регуляризатора сглаживания
    $$R (\Phi, \Theta) = \beta_0 \sum \limits_{t \in T_0} \sum \limits_{w \in W} \beta_{wt} \ln \varphi_{wt} + \alpha_0 \sum \limits_{d \in D_0} \sum \limits_{t \in T} \alpha_{td} \ln \theta_{td}$$
    зафиксировать столбцы матрицы $\Phi$, соответствующие релевантным темам, используя с достаточно большим коэффициентом
    \item Для выявления новых релевантных тем использовать регуляризатор декоррелирования, используя матрицу $\widetilde{\Phi}$ предыдущей модели:
        $$R(\Phi) = -\tau \sum \limits_{t \in T_+} \sum \limits_{s \in T_-} \sum \limits_{w \in W} \varphi_{wt} \widetilde{\varphi}_{ws} \to \max$$
        $$\varphi_{wt} = \norm \limits_{w \in W} \left(n_{wt} - \tau \varphi_{wt} [t \in T_+] \sum \limits_{s \in T_-} \widetilde{\varphi}_{ws}\right)$$
\end{itemize}
\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Вычислительный эксперимент}

В качестве коллекции текстов используется набор из $16 \ 449$ новостей, опубликованных на сайте Lenta.ru в период с мая по август $2008$-го года.
Предполагается разделение на $100$ тем. 

\begin{block}{Предобработка:}
\begin{itemize}
    \item Заголовок и текст каждой новости разбиваются на токены, далее происходит лемматизация.
    \item Далее по PMI отбирается $10 \ 000$ биграмм, которые характеризуют коллекцию текстов.
\end{itemize}
\end{block}

\textbf{Базовая модель:} TopicNet, $50$ предметных тем, без регуляризаторов на темы \\
\textbf{Новая модель:} TopicNet, $50$ предметных тем, регуляризатор сглаживания для тем $T_+$ с $\tau = {10}^{9}$, регуляризатор декоррелирования для тем из $T_-$

{\footnotesize \textit{Каждая последующая модель строится аналогично, используя данные модели на предыдущей итерации.}}

\end{frame}

\begin{frame}{Вычислительный эксперимент}
    \textbf{Внешний критерий:} количество тем в $T_+$, $T_0$, $T_-$.
    
    {\footnotesize Чем больше $|T_+|$ и меньше $|T_-|$, тем лучше.}

    \textbf{Внутренние критерии:}

    \begin{itemize}
        \item Перплексия
        $$\mathcal{P}_m (D; p) = \exp \left( - \frac{1}{n_m} \sum \limits_{d \in D} \sum \limits_{w \in W^m} n_{dw} \ln p (w \mid d) \right)$$
        \item Разреженность матрицы $\Phi$
        \item Средняя контрастность тем, где контрастность темы определяется как
        $$\text{con}_t = \frac{1}{|W_t|} \sum \limits_{w \in W_t} p(t \mid w), \ W_t = \{ w \in W \mid \varphi_{wt} > \frac{1}{|W|} \}$$
    \end{itemize}
\end{frame}

\begin{frame}{Вычислительный эксперимент}

    \begin{table}[]
        \centering
        \begin{tabular}{c|c|c|c|}
            Модель & $|T_+|$ & $|T_0|$ & $|T_-|$ \\
            \hline
            $M_0$ & $5$ & $1$ & $44$ \\
            $M_1$ & $7$ & $1$ & $42$ \\
            $M_2$ & $8$ & $1$ & $41$ \\
            $M_3$ & $8$ & $1$ & $41$
        \end{tabular}
        \caption{Данные по группам по пользовательской разметке}
        \label{tab:my_label}
    \end{table}

    На каждой итерации удалось сохранить ранее найденные релевантные темы.

\end{frame}

\begin{frame}{Вычислительный эксперимент}

\begin{columns}[c]
\column{0.5\textwidth}
\begin{figure}
\includegraphics[width=0.75\textwidth]{perplexity_v3}
\caption{Перплексия}
\end{figure}

\column{0.5\textwidth}
\begin{figure}
\includegraphics[width=0.75\textwidth]{sparsity_v3}
\caption{Разреженность $\Phi$}
\end{figure}
\end{columns}

\begin{figure}
\includegraphics[width=0.5\textwidth]{avg_contrast_v3}
\caption{Средняя контрастность тем}
\end{figure}

\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Заключение}
    \begin{block}{Результаты:}
    \begin{itemize}
        \item предложен метод итеративного улучшения тематической модели,
        \item показано, как использовать регулятор сглаживания для сохранения тем из $T_+$,
        \item предложен регуляризатор декоррелирования тем из $T_-$.
        
    \end{itemize}
    \end{block}
\end{frame}
%----------------------------------------------------------------------------------------------------------

\end{document} 
\end{frame}
%-----------------------------------------------------------------------------------------------------


\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{���������� ������}
\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{�������}
\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{�������������� �����������}
\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{����������}
\end{frame}
%----------------------------------------------------------------------------------------------------------
\end{document} 